<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Isobel Beasley" />

<meta name="date" content="2025-10-22" />

<title>Get full article text for GWAS Catalog studies</title>

<script src="site_libs/header-attrs-2.30/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">genomics_ancest_disease_dispar</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Get full article text for GWAS Catalog
studies</h1>
<h4 class="author">Isobel Beasley</h4>
<h4 class="date">2025-10-22</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2026-02-04
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong>
<code>genomics_ancest_disease_dispar/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20220216code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20220216)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20220216code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20220216)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomIJbeasleygenomicsancestdiseasedispartreed214580202f46f9078ed0eac3ab5a6ba32eb51d8targetblankd214580a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/tree/d214580202f46f9078ed0eac3ab5a6ba32eb51d8" target="_blank">d214580</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomIJbeasleygenomicsancestdiseasedispartreed214580202f46f9078ed0eac3ab5a6ba32eb51d8targetblankd214580a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/tree/d214580202f46f9078ed0eac3ab5a6ba32eb51d8" target="_blank">d214580</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rproj.user/
    Ignored:    .venv/
    Ignored:    Aus_School_Profile.xlsx
    Ignored:    SeniorSecondaryCompletionandAchievementInformation_2025.xlsx
    Ignored:    analysis/.DS_Store
    Ignored:    ancestry_dispar_env/
    Ignored:    code/.DS_Store
    Ignored:    code/full_text_conversion/.DS_Store
    Ignored:    data/.DS_Store
    Ignored:    data/RCDCFundingSummary_01042026.xlsx
    Ignored:    data/cdc/
    Ignored:    data/cohort/
    Ignored:    data/epmc/
    Ignored:    data/europe_pmc/
    Ignored:    data/gbd/.DS_Store
    Ignored:    data/gbd/IHME-GBD_2021_DATA-d8cf695e-1.csv
    Ignored:    data/gbd/IHME-GBD_2023_DATA-73cc01fd-1.csv
    Ignored:    data/gbd/gbd_2019_california_percent_deaths.csv
    Ignored:    data/gbd/ihme_gbd_2019_global_disease_burden_rate_all_ages.csv
    Ignored:    data/gbd/ihme_gbd_2019_global_paf_rate_percent_all_ages.csv
    Ignored:    data/gbd/ihme_gbd_2021_global_disease_burden_rate_all_ages.csv
    Ignored:    data/gbd/ihme_gbd_2021_global_paf_rate_percent_all_ages.csv
    Ignored:    data/gwas_catalog/
    Ignored:    data/icd/.DS_Store
    Ignored:    data/icd/2025AA/
    Ignored:    data/icd/IHME_GBD_2019_COD_CAUSE_ICD_CODE_MAP_Y2020M10D15.XLSX
    Ignored:    data/icd/IHME_GBD_2019_NONFATAL_CAUSE_ICD_CODE_MAP_Y2020M10D15.XLSX
    Ignored:    data/icd/IHME_GBD_2021_COD_CAUSE_ICD_CODE_MAP_Y2024M05D16.XLSX
    Ignored:    data/icd/IHME_GBD_2021_NONFATAL_CAUSE_ICD_CODE_MAP_Y2024M05D16.XLSX
    Ignored:    data/icd/UK_Biobank_master_file.tsv
    Ignored:    data/icd/cdc_valid_icd10_Sep_23_2025.xlsx
    Ignored:    data/icd/cdc_valid_icd9_Sep_23_2025.xlsx
    Ignored:    data/icd/hp_umls_mapping.csv
    Ignored:    data/icd/lancet_conditions_icd10.xlsx
    Ignored:    data/icd/manual_disease_icd10_mappings.xlsx
    Ignored:    data/icd/mondo_umls_mapping.csv
    Ignored:    data/icd/phecode_international_version_unrolled.csv
    Ignored:    data/icd/phecode_to_icd10_manual_mapping.xlsx
    Ignored:    data/icd/semiautomatic_ICD-pheno.txt
    Ignored:    data/icd/semiautomatic_ICD-pheno_UKB_subset.txt
    Ignored:    data/icd/umls-2025AA-mrconso.zip
    Ignored:    figures/
    Ignored:    output/.DS_Store
    Ignored:    output/abstracts/
    Ignored:    output/doccano/
    Ignored:    output/fulltexts/
    Ignored:    output/gwas_cat/
    Ignored:    output/gwas_cohorts/
    Ignored:    output/icd_map/
    Ignored:    output/trait_ontology/
    Ignored:    pubmedbert-cohort-ner-model/
    Ignored:    pubmedbert-cohort-ner/
    Ignored:    renv/
    Ignored:    spacyr_venv/
    Ignored:    test_37689528.xml

Untracked files:
    Untracked:  code/full_text_conversion/elsevier_to_jats_v2.R
    Untracked:  code/full_text_conversion/elsevier_to_jats_v3.R
    Untracked:  code/full_text_conversion/elsevier_to_jats_v4.R
    Untracked:  code/full_text_conversion/elsevier_to_jats_v5.R
    Untracked:  code/full_text_conversion/fix_elsevier_xml.py
    Untracked:  code/full_text_conversion/testing_fix_elsevier.R
    Untracked:  debug_elsevier.R
    Untracked:  schools.R
    Untracked:  testing.R

Unstaged changes:
    Modified:   analysis/disease_inves_by_ancest.Rmd
    Modified:   analysis/get_dbgap_ids.Rmd
    Modified:   analysis/index.Rmd
    Modified:   analysis/map_trait_to_icd10.Rmd
    Modified:   analysis/missing_cohort_info.Rmd
    Modified:   analysis/replication_ancestry_bias.Rmd
    Modified:   analysis/specific_aims_stats.Rmd
    Modified:   analysis/text_for_cohort_labels.Rmd
    Modified:   code/full_text_conversion/elsevier_to_jats.R

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">
<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/get_full_text.Rmd</code>) and
HTML (<code>docs/get_full_text.html</code>) files. If you’ve configured
a remote Git repository (see <code>?wflow_git_remote</code>), click on
the hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/d214580202f46f9078ed0eac3ab5a6ba32eb51d8/analysis/get_full_text.Rmd" target="_blank">d214580</a>
</td>
<td>
IJbeasley
</td>
<td>
2026-02-04
</td>
<td>
Getting full text from publisher APIs
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/6ba1e1f3694b7aa9e15026fa680ea361598a33b7/docs/get_full_text.html" target="_blank">6ba1e1f</a>
</td>
<td>
IJbeasley
</td>
<td>
2026-01-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/b43e9a99e0280f45d629a78b0ab176516cadc479/analysis/get_full_text.Rmd" target="_blank">b43e9a9</a>
</td>
<td>
IJbeasley
</td>
<td>
2026-01-12
</td>
<td>
Update getting full text
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/ac0d1a7c1691a458765321cbdc43867e43f9a6ee/docs/get_full_text.html" target="_blank">ac0d1a7</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/8642872a5fe5572b64be5cdd6d68045f9766ab36/docs/get_full_text.html" target="_blank">8642872</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/da4d7305c55369025b3f6e89b5faa00987a7e50a/analysis/get_full_text.Rmd" target="_blank">da4d730</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Now run on all texts
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/fb5cfd9414e0621d6167b74b3f189911f4be6498/docs/get_full_text.html" target="_blank">fb5cfd9</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/8ed4c37b75a352304f5f4d5bdb5e2f43bdc3183a/analysis/get_full_text.Rmd" target="_blank">8ed4c37</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Now run on all texts
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/861028395fe749895e6b71000052500c51d195fd/docs/get_full_text.html" target="_blank">8610283</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/7d504e3db75bc28e18a04e156a746e10a41d3faa/analysis/get_full_text.Rmd" target="_blank">7d504e3</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
More fixing of download full text
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/16f4c191dd3ff8d584744a999026381e72bc72b6/docs/get_full_text.html" target="_blank">16f4c19</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/3df4096aa7693c669469c94ef3cb12954f01b243/analysis/get_full_text.Rmd" target="_blank">3df4096</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-27
</td>
<td>
Update + improve full text downloading - test run
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/IJbeasley/genomics_ancest_disease_dispar/1439951c3ae14ee8cdfba142d63d9f99b527269c/docs/get_full_text.html" target="_blank">1439951</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-24
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/IJbeasley/genomics_ancest_disease_dispar/blob/481aebe82123251dcc9708ca5972905d12e966c5/analysis/get_full_text.Rmd" target="_blank">481aebe</a>
</td>
<td>
IJbeasley
</td>
<td>
2025-10-24
</td>
<td>
Update code for getting full texts
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="required-packages" class="section level2">
<h2>Required packages</h2>
<pre class="r"><code>library(httr)
library(xml2)
library(stringr)
library(here)
library(dplyr)
library(data.table)</code></pre>
</div>
<div id="get-pmcids" class="section level1">
<h1>Get PMCIDs</h1>
<div id="get-pubmed-ids-from-gwas-catalog" class="section level2">
<h2>Get Pubmed ids from GWAS catalog</h2>
<pre class="r"><code># gwas_study_info &lt;- data.table::fread(here::here(&quot;output/gwas_cat/gwas_study_info_trait_group_l2.csv&quot;))

## Step 1: 
# get only relevant disease studies
# gwas_study_info &lt;- data.table::fread(here::here(&quot;output/gwas_cat/gwas_study_info_trait_group_l2.csv&quot;))
gwas_study_info &lt;- data.table::fread(here::here(&quot;output/icd_map/gwas_study_gbd_causes.csv&quot;))

gwas_study_info = gwas_study_info |&gt;
  dplyr::rename_with(~ gsub(&quot; &quot;, &quot;_&quot;, .x))

# filter out infectious diseases
gwas_study_info &lt;- gwas_study_info |&gt;
    dplyr::filter(!cause %in% c(&quot;HIV/AIDS&quot;,
                             &quot;Tuberculosis&quot;,
                             &quot;Malaria&quot;,
                             &quot;Lower respiratory infections&quot;,
                             &quot;Diarrhoeal diseases&quot;,
                             &quot;Neonatal disorders&quot;,
                             &quot;Tetanus&quot;,
                             &quot;Diphtheria&quot;,
                             &quot;Pertussis&quot; ,
                             &quot;Measles&quot;,
                             &quot;Maternal disorders&quot;))

# gwas_study_info &lt;- gwas_study_info |&gt;
#   dplyr::filter(DISEASE_STUDY == TRUE)

print(&quot;Number of disease studies to get full texts for:&quot;)</code></pre>
<pre><code>[1] &quot;Number of disease studies to get full texts for:&quot;</code></pre>
<pre class="r"><code>pmids &lt;- unique(gwas_study_info$PUBMED_ID)
length(pmids)</code></pre>
<pre><code>[1] 821</code></pre>
</div>
<div id="convert-pubmed-ids-to-pmcids" class="section level2">
<h2>Convert Pubmed IDs to PMCIDs</h2>
<pre class="r"><code># get PMID to PMCID mapping using Europe PMC file:
convert_pmid_df &lt;- fread(here::here(&quot;data/europe_pmc/PMID_PMCID_DOI.csv&quot;))

convert_pmid_df &lt;- convert_pmid_df |&gt;
  dplyr::rename(pmcids = PMCID
                ) |&gt;
  dplyr::mutate(pmcids = ifelse(is.na(pmcids),
                                &quot;&quot;,
                                pmcids
                                )
                )

convert_pmid_df &lt;-
  convert_pmid_df |&gt;
  dplyr::filter(!is.na(PMID))

converted_ids = 
  convert_pmid_df |&gt;
  filter(PMID %in% pmids)

data.table::fwrite(converted_ids,
                   here::here(&quot;output/fulltexts/pmid_to_pmcid_mapping.csv&quot;)
                   )</code></pre>
<pre class="r"><code>converted_ids &lt;- data.table::fread(here::here(&quot;output/fulltexts/pmid_to_pmcid_mapping.csv&quot;))

print(&quot;Head of pmid to pmcid mapping data.frame:&quot;)</code></pre>
<pre><code>[1] &quot;Head of pmid to pmcid mapping data.frame:&quot;</code></pre>
<pre class="r"><code>head(converted_ids)</code></pre>
<pre><code>       PMID     pmcids                                           DOI
      &lt;int&gt;     &lt;char&gt;                                        &lt;char&gt;
1: 17223258             https://doi.org/10.1016/j.canlet.2006.11.029
2: 17293876                      https://doi.org/10.1038/nature05616
3: 17434096 PMC2613843 https://doi.org/10.1016/s1474-4422(07)70081-9
4: 17460697                           https://doi.org/10.1038/ng2043
5: 17463246                  https://doi.org/10.1126/science.1142358
6: 17463248 PMC3214617       https://doi.org/10.1126/science.1142382</code></pre>
<pre class="r"><code>print(&quot;Dimensions of pmid to pmcid mapping data.frame:&quot;)</code></pre>
<pre><code>[1] &quot;Dimensions of pmid to pmcid mapping data.frame:&quot;</code></pre>
<pre class="r"><code>dim(converted_ids)</code></pre>
<pre><code>[1] 821   3</code></pre>
<pre class="r"><code>length(pmids)</code></pre>
<pre><code>[1] 821</code></pre>
<pre class="r"><code>print(&quot;All pmids are in this data.frame, but some don&#39;t have pmcid mapping&quot;)</code></pre>
<pre><code>[1] &quot;All pmids are in this data.frame, but some don&#39;t have pmcid mapping&quot;</code></pre>
<pre class="r"><code>print(&quot;Number of pmids without pmcid mapping:&quot;)</code></pre>
<pre><code>[1] &quot;Number of pmids without pmcid mapping:&quot;</code></pre>
<pre class="r"><code>converted_ids |&gt;
  filter(pmcids == &quot;&quot;) |&gt;
  dim()</code></pre>
<pre><code>[1] 173   3</code></pre>
</div>
</div>
<div id="download-full-texts-from-european-pmc" class="section level1">
<h1>Download full texts from European PMC</h1>
<pre class="r"><code>pmcids &lt;-
converted_ids$pmcids |&gt;
  unique()

pmcids &lt;- pmcids[pmcids != &quot;&quot;]

length(pmcids)</code></pre>
<pre><code>[1] 648</code></pre>
<pre class="r"><code>print(&quot;Percentage of pmids with pmcid:&quot;)</code></pre>
<pre><code>[1] &quot;Percentage of pmids with pmcid:&quot;</code></pre>
<pre class="r"><code>round(100 * length(pmcids) / length(pmids), digits = 2)</code></pre>
<pre><code>[1] 78.93</code></pre>
<pre class="r"><code>download_pmc_text &lt;- function(pmcid, 
                              out_dir = here::here(&quot;output/fulltexts/europe_pmc/&quot;)
                              ) {


  url_xml &lt;- paste0(&quot;https://www.ebi.ac.uk/&quot;,
                    &quot;europepmc/webservices/rest/&quot;,
                    pmcid,
                    &quot;/fullTextXML&quot;
                    )
  
  resp &lt;- GET(url_xml)
  
  # MED/20708005
  
  # ---- Fallback URL ----
  if(status_code(resp) != 200){
    
    #print(paste0(&quot;Trying alternative URL for &quot;, pmcid))
    
    url_xml &lt;- paste0(&quot;https://europepmc.org/&quot;,
                       &quot;oai.cgi?verb=GetRecord&quot;,
                       &quot;&amp;metadataPrefix=pmc&quot;,
                       &quot;&amp;identifier=oai:europepmc.org:&quot;,
                       pmcid)
    
    resp &lt;- GET(url_xml)
  
  }
  
  # ---- Fail if still bad ----
  if(status_code(resp) != 200){
    
  #message(&quot;Failed to fetch XML for &quot;, pmcid)
  
  return(NULL)
    
  }
  
  # ---- Parse XML ----
  xml_content &lt;- read_xml(
    content(resp, 
            as = &quot;text&quot;, 
            encoding = &quot;UTF-8&quot;)
  )
  
  xml_content &lt;- read_xml(content(resp,
                                  as = &quot;text&quot;,
                                  encoding = &quot;UTF-8&quot;)
                          )
  
  article_node = xml_find_first(xml_content, 
                               &quot;//*[local-name() = &#39;article&#39;]&quot;
                               )
  
   if (is.na(article_node)) {
    message(&quot;No &lt;article&gt; node found for &quot;, pmcid)
     
    return(NULL)
   }
  
    # --- Save ---
  write_xml(article_node, 
            paste0(out_dir, pmcid, &quot;.xml&quot;)
            )
  
} 


for(article in pmcids[pmcids != &quot;&quot;]){

download_pmc_text(article)

}</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files&quot;</code></pre>
<pre class="r"><code>print(&quot;From European PMC:&quot;)</code></pre>
<pre><code>[1] &quot;From European PMC:&quot;</code></pre>
<pre class="r"><code>n_euro_pmc &lt;- length(list.files(here::here(&quot;output/fulltexts/europe_pmc/&quot;),
                  pattern = &quot;\\.xml$&quot;)
       )

print(&quot;Percentage of pmids with full text from European PMC:&quot;)</code></pre>
<pre><code>[1] &quot;Percentage of pmids with full text from European PMC:&quot;</code></pre>
<pre class="r"><code>round(100 * n_euro_pmc / length(pmids), digits = 2)</code></pre>
<pre><code>[1] 63.82</code></pre>
</div>
<div id="download-full-texts-from-ncbi-cloud-service"
class="section level1">
<h1>Download full texts from NCBI Cloud Service</h1>
<p>For remaining PMCIDs / PMIDs without full text, try downloading using
NCBI Cloud Service.</p>
<pre class="bash"><code>
# get list of pmcids with full text - author_manuscript available
# available in XML and plain text for text mining purposes.
aws s3 cp s3://pmc-oa-opendata/author_manuscript/txt/metadata/txt/author_manuscript.filelist.txt output/fulltexts/aws_locations/  --no-sign-request 

# get list of pmcids with full text - non-commercial use
# oa_noncomm 
aws s3 cp s3://pmc-oa-opendata/oa_noncomm/txt/metadata/txt/oa_noncomm.filelist.txt output/fulltexts/aws_locations/  --no-sign-request 

# get list of pmcids with full text, commercial list
# oa_comm
aws s3 cp s3://pmc-oa-opendata/oa_comm/txt/metadata/txt/oa_comm.filelist.txt output/fulltexts/aws_locations/  --no-sign-request 

# get list of pmcids with full text, commercial list
# oa_other
aws s3 cp s3://pmc-oa-opendata/oa_other/txt/metadata/txt/oa_other.filelist.txt output/fulltexts/aws_locations/  --no-sign-request 
</code></pre>
<div id="identify-full-texts-already-downloaded-through-european-pmc"
class="section level2">
<h2>Identify full texts already downloaded through European PMC</h2>
<pre class="r"><code>europeanpmc_full_texts &lt;- 
list.files(here::here(&quot;output/fulltexts/europe_pmc&quot;),
                  pattern = &quot;\\.xml&quot;
           )

# get pmcids of these files
europeanpmc_full_texts &lt;-
  gsub(&quot;\\.xml$&quot;, 
       &quot;&quot;, 
       europeanpmc_full_texts
       ) </code></pre>
</div>
<div
id="get-ncbi-download-paths-for-remaining-full-texts-where-avaliable"
class="section level2">
<h2>Get NCBI download paths for remaining full texts (where
avaliable)</h2>
<pre class="r"><code>left_over_pmcids = pmcids[!pmcids %in% europeanpmc_full_texts]

print(&quot;Number of remaining pmcids without full text:&quot;)</code></pre>
<pre><code>[1] &quot;Number of remaining pmcids without full text:&quot;</code></pre>
<pre class="r"><code>length(left_over_pmcids)</code></pre>
<pre><code>[1] 220</code></pre>
<pre class="r"><code>author_manu = data.table::fread(here::here(&quot;output/fulltexts/aws_locations/author_manuscript.filelist.txt&quot;))

oa_noncomm = data.table::fread(here::here(&quot;output/fulltexts/aws_locations/oa_noncomm.filelist.txt&quot;))

oa_comm = data.table::fread(here::here(&quot;output/fulltexts/aws_locations/oa_comm.filelist.txt&quot;))

author_manu_to_get &lt;-
author_manu |&gt;
  dplyr::filter(AccessionID %in% left_over_pmcids)

print(&quot;Number of papers to download in Author Manuscripts section:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers to download in Author Manuscripts section:&quot;</code></pre>
<pre class="r"><code>nrow(author_manu_to_get)</code></pre>
<pre><code>[1] 135</code></pre>
<pre class="r"><code>oa_noncomm_to_get = 
oa_noncomm |&gt;
#  dplyr::filter(PMID %in% names(left_over_pmcids)) 
  dplyr::filter(AccessionID %in% left_over_pmcids)

oa_comm_to_get = 
oa_comm |&gt;
#  dplyr::filter(PMID %in% names(left_over_pmcids)) 
  dplyr::filter(AccessionID %in% left_over_pmcids)

print(&quot;Number of papers to download in Open Access PMC section:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers to download in Open Access PMC section:&quot;</code></pre>
<pre class="r"><code>nrow(oa_noncomm_to_get) + nrow(oa_comm_to_get)</code></pre>
<pre><code>[1] 1</code></pre>
<pre class="r"><code>oa_noncomm_to_get &lt;-
  oa_noncomm_to_get |&gt;
  dplyr::filter(!c(AccessionID %in% author_manu_to_get$AccessionID))

oa_ncomm_to_get &lt;-
  oa_noncomm_to_get |&gt;
  dplyr::filter(!c(AccessionID %in% author_manu_to_get$AccessionID))


file_paths = 
c(oa_noncomm_to_get$Key,
  oa_comm_to_get$Key,
  author_manu_to_get$Key)

file_paths &lt;- str_replace_all(file_paths,
                              pattern = &quot;txt&quot;,
                              replacement = &quot;xml&quot;)</code></pre>
</div>
<div id="download-remaining-full-texts-from-ncbi-cloud-service"
class="section level2">
<h2>Download remaining full texts from NCBI Cloud Service</h2>
<pre class="r"><code>writeLines(
  file_paths,
  here::here(&quot;output/fulltexts/aws_locations/selected_paths.txt&quot;)
)

system(
  paste(
    &quot;xargs -I {} aws s3 cp&quot;,
    &quot;s3://pmc-oa-opendata/{}&quot;,
    shQuote(here::here(&quot;output/fulltexts/ncbi_cloud/&quot;)),
    &quot;--no-sign-request&quot;,
    &quot;&lt;&quot;,
    shQuote(here::here(&quot;output/fulltexts/aws_locations/selected_paths.txt&quot;))
  )
)</code></pre>
<pre class="r"><code># not_available = left_over_pmcids[!c(left_over_pmcids %in% 
#                                           c(oa_noncomm_to_get$AccessionID, 
#                                             oa_comm_to_get$AccessionID,
#                                             author_manu_to_get$AccessionID)
#                                           )]

# get list of pmcids already retrieved
pmcids_retrieved &lt;- 
list.files(c(here::here(&quot;output/fulltexts/europe_pmc&quot;),
             here::here(&quot;output/fulltexts/ncbi_cloud/&quot;)
             ),
             pattern = &quot;\\.xml$&quot;
)

pmcids_retrieved &lt;-
  gsub(&quot;\\.xml$&quot;, 
       &quot;&quot;, 
       pmcids_retrieved
       )

pmids_retrieved &lt;-
converted_ids  |&gt;
  filter(pmcids %in% pmcids_retrieved) |&gt;
  pull(PMID)

all_pmids &lt;- unique(gwas_study_info$PUBMED_ID)

not_available &lt;- all_pmids[!c(all_pmids %in% pmids_retrieved)] 

print(&quot;Percentage of pmids with full text from NCBI Cloud Service:&quot;)</code></pre>
<pre><code>[1] &quot;Percentage of pmids with full text from NCBI Cloud Service:&quot;</code></pre>
<pre class="r"><code>100 * (n_euro_pmc - length(not_available)) / length(pmids)</code></pre>
<pre><code>[1] 32.52132</code></pre>
<pre class="r"><code>print(&quot;Percentage of pmids without full text from either European PMC or NCBI Cloud Service:&quot;)</code></pre>
<pre><code>[1] &quot;Percentage of pmids without full text from either European PMC or NCBI Cloud Service:&quot;</code></pre>
<pre class="r"><code>100 * length(not_available) / length(pmids)</code></pre>
<pre><code>[1] 31.30329</code></pre>
</div>
</div>
<div id="download-from-publisher-uses-dois" class="section level1">
<h1>Download from publisher (uses dois)</h1>
<div id="get-dois-for-remaining-articles-to-get-full-full-text"
class="section level2">
<h2>Get dois for remaining articles to get full full text</h2>
<pre class="r"><code>doi_information &lt;-
converted_ids |&gt;
  filter(PMID %in% not_available)</code></pre>
</div>
<div id="function-to-get-crossref-meta-data-link-information"
class="section level2">
<h2>Function to get CrossRef meta-data / link information:</h2>
<pre class="r"><code>library(rcrossref)
library(httr)

# Get download links from Crossref
get_crossref_links &lt;- function(doi) {
  
  # Query Crossref for the article
  works &lt;- cr_works(dois = doi)
  
  # keep links for xml or text-mining 
  links &lt;- works$data$link[[1]]
  
  if(is.null(links)){
    link_data &lt;- data.frame(doi = doi,
                            URL = NA,
                            content.type = NA,
                            content.version = NA,
                            intended.application = NA)
    return(link_data)
  }
  
  links &lt;- 
  links |&gt;
    filter(intended.application == &quot;text-mining&quot; | content.type == &quot;application/xml&quot;
             ) 
  
  
  
  if(nrow(links) == 0){
    link_data &lt;- data.frame(doi = doi,
                            URL = NA,
                            content.type = NA,
                            content.version = NA,
                            intended.application = NA)
  } else{
  
  link_data &lt;- 
  data.frame(doi = doi,
             links)
  
  }

  return(link_data)
} </code></pre>
</div>
<div id="download-xml-full-texts-from-publisher-links"
class="section level2">
<h2>Download xml full texts from publisher links</h2>
<div id="download-full-text-from-elsevier-api-links"
class="section level3">
<h3>Download full text from Elsevier API links</h3>
<ul>
<li>Can download full text (xmls etc.) for open access articles using
Elsevier API by getting token from: <a href="https://dev.elsevier.com/"
class="uri">https://dev.elsevier.com/</a></li>
<li>Can download full text using this token for subscribed content (for
non-commercial, academic purposes) after contacting Elsevier using the
following information: <a
href="https://dev.elsevier.com/api_key_settings.html"
class="uri">https://dev.elsevier.com/api_key_settings.html</a></li>
<li>XMLS are in Elsevier’s proprietary XML format (not JATS)</li>
</ul>
<pre class="r"><code># elsevier dois:
elsevier_doi_patterns &lt;-    &quot;10.1016|10.1053|10.1086|10.1194|10.1593|10.1097/jto.&quot;

elsevier_dois &lt;- grep(elsevier_doi_patterns,
                          doi_information$DOI,
                           value = TRUE
                           )

print(&quot;Number of papers potentially can get from Elsevier:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from Elsevier:&quot;</code></pre>
<pre class="r"><code>length(elsevier_dois)</code></pre>
<pre><code>[1] 41</code></pre>
<pre class="r"><code>elsevier_api_key &lt;- Sys.getenv(&quot;ELSEVIER_API_KEY&quot;)

elsevier_doi_info &lt;- str_remove_all(pattern = &quot;https://doi.org/&quot;, 
                                     string = elsevier_dois)

# get pmids for elsevier dois
pmids_elsevier &lt;- doi_information |&gt;
  filter(DOI %in% elsevier_dois) |&gt;
  mutate(DOI = str_remove_all(DOI,
                                 pattern = &quot;https://doi.org/&quot;
                                 )
         ) |&gt;
rename_with(~tolower(.x)) 

# get elsevier full text links from crossref
elsevier_link_df &lt;- purrr::map(elsevier_doi_info,
                              ~get_crossref_links(.x)
                              ) |&gt; 
  bind_rows()

print(&quot;Number of Elsevier links retrieved from Crossref:&quot;)
nrow(elsevier_link_df)

print(&quot;Number of xml links retrieved from Elsevier links:&quot;)
elsevier_link_df |&gt;
  filter(content.type == &quot;text/xml&quot;) |&gt;
  nrow()

elsevier_links &lt;- elsevier_link_df |&gt;
                  filter(!is.na(URL)) 

elsevier_links &lt;- elsevier_links |&gt;
  left_join(pmids_elsevier,
            by = c(&quot;doi&quot;)
            )

# get only xml links
elsevier_links &lt;-
elsevier_links |&gt;
  filter(content.type == &quot;text/xml&quot;) 


download_elsevier_text &lt;- function(url, 
                                   api_key,
                                   pmid,
                                   out_dir = here::here(&quot;output/fulltexts/elsevier/elsevier_xml/&quot;)) {
  
  # if(file.exists(paste0(out_dir, pmid, &quot;.xml&quot;))|file.exists(paste0(out_dir, pmid, &quot;.txt&quot;))
  #    ){
  #   return(TRUE)
  # }
  
  response &lt;- GET(url,
                  add_headers(&quot;X-ELS-APIKey&quot; = api_key)
                  )
  
  # if (status_code(response) != 200) {
  #   message(&quot;Failed to fetch text for &quot;, pmid)
  #   return(FALSE)
  #   
  # }
  
  ct &lt;- headers(response)[[&quot;content-type&quot;]]
  
  #print(ct)
  
  if(grepl(&quot;text/plain&quot;, ct)){
    message(&quot;Received plain text for &quot;, pmid, 
            &quot; - skipping for now.&quot;
            )
    
    return(TRUE)
    
    # text_content &lt;- content(response, type = &quot;text/plain&quot;)
    # 
    # writeLines(text_content,
    #            paste0(out_dir, pmid, &quot;.txt&quot;),
    #            useBytes = TRUE)
    
    
  } else {
  
  xml_content &lt;- content(response, 
                         encoding = &quot;UTF-8&quot;,
                         type = &quot;text/xml&quot;)
  
  
  article_node &lt;- xml2::xml_find_first(
    xml_content,
    &quot;.//*[local-name()=&#39;originalText&#39;]&quot;
)
  
      xml2::write_xml(article_node, 
                        file = paste0(out_dir, pmid, &quot;.xml&quot;)
    )
      
  }
    
  # writeLines(text_content,
  #            paste0(out_dir, pmid, &quot;.txt&quot;),
  #            useBytes = TRUE)
  
}

purrr::walk2(elsevier_links$URL,
              elsevier_links$pmid,
                ~download_elsevier_text(url = .x,
                                        api_key = elsevier_api_key,
                                        pmid = .y)
                )</code></pre>
<p>Convert Elsevier xmls to JATS xml files</p>
<pre class="bash"><code>
mkdir -p output/fulltexts/elsevier/xml

for file in output/fulltexts/elsevier/elsevier_xml/*.xml; do 
    filename=$(basename &quot;$file&quot;)
    Rscript code/full_text_conversion/elsevier_to_jats_v4.R &quot;$file&quot; &quot;output/fulltexts/elsevier/xml/${filename%.xml}.xml&quot;
done
</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (xml) from Elsevier:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Elsevier:&quot;</code></pre>
<pre class="r"><code>list.files(here::here(&quot;output/fulltexts/elsevier/elsevier_xml/&quot;),
             pattern = &quot;\\.xml$&quot;
             ) |&gt;
  length()</code></pre>
<pre><code>[1] 41</code></pre>
</div>
<div id="download-full-text-from-sage" class="section level3">
<h3>Download full text from Sage</h3>
<p>Policies:</p>
<ul>
<li>Permitted for non-commercial text mining with institutional
access</li>
<li><a
href="https://journals.sagepub.com/page/policies/text-and-data-mining"
class="uri">https://journals.sagepub.com/page/policies/text-and-data-mining</a></li>
</ul>
<pre class="r"><code>sage_doi_patterns &lt;- &quot;10.1177|10.1089&quot;

sage_links &lt;-
  grep(sage_doi_patterns,
       doi_information$DOI,
       value = TRUE)

sage_links &lt;- str_remove_all(pattern = &quot;https://doi.org/&quot;, 
                              string = sage_links)

sage_link_df &lt;- purrr::map(sage_links, 
                      ~get_crossref_links(.x)) |&gt; 
  bind_rows()


# then had to download manually using provided xml links
# to use institutional login details 
# http://www.liebertpub.com/doi/full-xml/10.1089/omi.2017.0019
# https://journals.sagepub.com/doi/full-xml/10.1177/00220345211051967
# https://journals.sagepub.com/doi/full-xml/10.1177/0271678X211066299
# these are in JATS .xml format

# saved to output/fulltexts/sage
length(sage_links)</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (xml) from Sage:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Sage:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/sage&quot;),
             pattern = &quot;\\.xml$&quot;
)
)</code></pre>
<pre><code>[1] 3</code></pre>
</div>
<div id="download-full-text-from-springer-nature-open-access-api"
class="section level3">
<h3>Download full text from Springer Nature Open Access API</h3>
<ul>
<li>JATS xml format</li>
</ul>
<pre class="r"><code>springer_nature_links &lt;-
  grep(&quot;nature|10.1038/ng|10.1007/s0|10.1007|10.1038/ejhg|10.1038/tpj|10.1038/jhg|10\\.1038/|10\\.1007/&quot;,
       doi_information$DOI,
       value = TRUE)

springer_nature_links &lt;- str_remove_all(pattern = &quot;https://doi.org/&quot;, 
                                        string = springer_nature_links)




pmids &lt;- doi_information %&gt;%
  filter(DOI %in% paste0(&quot;https://doi.org/&quot;, 
                         springer_nature_links)) %&gt;%
  pull(PMID)

check_springer_oa &lt;- function(doi, 
                              api_key,
                              pmids,
                              out_dir = here::here(&quot;output/fulltexts/springer_nature/&quot;)) {
  
  if(file.exists(paste0(out_dir, pmids, &quot;.xml&quot;))){
    return(data.frame(doi = doi, 
                      openaccess = TRUE)
    )
  }
  
  url&lt;- paste0(&quot;https://api.springernature.com/openaccess/jats?&quot;,
               &quot;api_key=&quot;, oa_api_key,
               &quot;&amp;q=&quot;, doi
  )
  
  response &lt;- GET(url)
  
  # if the request fails, return data.frame with doi and oa = F
  if (status_code(response) != 200) {
    return(data.frame(doi = doi, 
                      openaccess = FALSE)
           )
  } else {
    
    xml_content &lt;- content(response)
    
    article_node &lt;- xml2::xml_find_all(xml_content, &quot;.//records&quot;)
    
  if (xml2::xml_text(article_node) == &quot;&quot;) {
    
    return(data.frame(doi = doi, 
                      openaccess = FALSE)
    )
    
  }
    
  }
    
    xml2::write_xml(article_node, 
              paste0(out_dir, pmids, &quot;.xml&quot;)
    )
    
    return(data.frame(doi = doi, 
                      openaccess = TRUE)
    )
    
}
  
  oa_status &lt;-
purrr::map2(springer_nature_links,
           pmids,
           ~check_springer_oa(doi = .x,
                              api_key = oa_api_key,
                              pmids = .y)
)
  
  
  oa_status_df &lt;- oa_status |&gt; bind_rows()
  
  oa_status_df |&gt; group_by(openaccess) |&gt;
    summarise(n = n())
  
  oa_status_df |&gt;
    filter(openaccess == FALSE)</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (xml) from Springer Nature:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Springer Nature:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/springer_nature&quot;),
             pattern = &quot;\\.xml$&quot;
)
)</code></pre>
<pre><code>[1] 67</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded html files from Springer Nature:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded html files from Springer Nature:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/springer_nature&quot;),
                  recursive = TRUE,
             pattern = &quot;\\.html$&quot;
)
)</code></pre>
<pre><code>[1] 6</code></pre>
</div>
<div id="download-full-text-from-wiley" class="section level3">
<h3>Download full text from Wiley</h3>
<p>Wiley Text &amp; Data-mining Policy: <a
href="https://onlinelibrary.wiley.com/library-info/resources/text-and-datamining"
class="uri">https://onlinelibrary.wiley.com/library-info/resources/text-and-datamining</a></p>
<ul>
<li>Can download PDFs using their API with token</li>
<li>Download xmls using <a
href="https://onlinelibrary.wiley.com/doi/full-xml/%5BDOI%5D"
class="uri">https://onlinelibrary.wiley.com/doi/full-xml/[DOI]</a></li>
</ul>
<p>These xmls are in Wiley’s proprietary XML format, not JATS.</p>
<pre class="r"><code>wiley_dois &lt;- grep(&quot;10\\.1002/|10\\.1111/&quot;, 
                   doi_information$DOI, 
                   value = TRUE)

wiley_dois &lt;- str_remove_all(wiley_dois, &quot;https://doi.org/&quot;)

print(&quot;Number of papers potentially can get from Wiley:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from Wiley:&quot;</code></pre>
<pre class="r"><code>length(wiley_dois)</code></pre>
<pre><code>[1] 24</code></pre>
<pre class="r"><code>pmids_wiley_dois &lt;- doi_information %&gt;%
  filter(DOI %in% paste0(&quot;https://doi.org/&quot;,
                         wiley_dois)
                         ) %&gt;%
  pull(PMID)

download_wiley_pdf&lt;- function(doi,
                   api_key,
                   pmids,
                   output_dir = here::here(&quot;output/fulltexts/wiley/pdf/&quot;)){
  
  # check files doesn&#39;t already exist
  if(file.exists(paste0(output_dir, pmids, &quot;.pdf&quot;))){
    return(NULL)
  }
  
  curl_command &lt;- paste0(&#39;curl -L -H &quot;Wiley-TDM-Client-Token:&#39;,
                         wiley_api,
                         &#39;&quot; https://api.wiley.com/onlinelibrary/tdm/v1/articles/&#39;,
                         doi, 
                         &#39; -o &#39;, output_dir, pmids, &#39;.pdf&#39;
  )
  
  print(curl_command)

system(curl_command)

}

purrr::walk2(wiley_dois,
             pmids_wiley_dois,
             ~ download_wiley_pdf(.x, wiley_api, .y)
)

# remove zero byte files - ? I think these are failed downloads as not open access
system(&quot;find output/fulltexts/wiley/pdf -type f -size 0 -delete&quot;)

# xmls downloaded manually using https://onlinelibrary.wiley.com/doi/full-xml/[DOI]
# downloaded to fulltexts/wiley/wiley_xml</code></pre>
<p>As xml files are in Wiley format, convert JATS XML (1.1) format to be
consistent with PubMed etc.</p>
<pre class="bash"><code>
mkdir -p output/fulltexts/wiley/xml

for file in output/fulltexts/wiley/wiley_xml/*.xml; do 
    filename=$(basename &quot;$file&quot;)
    Rscript code/full_text_conversion/wiley_to_jats.R &quot;$file&quot; &quot;output/fulltexts/wiley/xml/${filename%.xml}.xml&quot;
done
</code></pre>
<pre class="r"><code># how many wiley full text xml downloaded
print(&quot;Number of downloaded full text files (xml) from Wiley:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Wiley:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/wiley/xml/&quot;), 
                  recursive = TRUE,
                  pattern = &quot;\\.xml$&quot;))</code></pre>
<pre><code>[1] 24</code></pre>
<pre class="r"><code># how many wiley pdfs downloaded
print(&quot;Number of downloaded full text files (pdf) from Wiley:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (pdf) from Wiley:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/wiley/&quot;), 
                  recursive = TRUE,
                  pattern = &quot;\\.pdf$&quot;))</code></pre>
<pre><code>[1] 8</code></pre>
</div>
</div>
<div id="download-html-full-texts-from-publisher-links"
class="section level2">
<h2>Download html full texts from publisher links</h2>
<div id="download-full-text-from-bmj-journals" class="section level3">
<h3>Download full text from BMJ Journals</h3>
<p>TDM policy: <a
href="https://bmjgroup.com/text-and-data-mining-tdm-policy/"
class="uri">https://bmjgroup.com/text-and-data-mining-tdm-policy/</a></p>
<pre class="r"><code>bmj_doi_patterns &lt;- &quot;10.1136/gutjnl|10.1136/jmedgenet&quot;

bmj_links &lt;-
  grep(bmj_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from BMJ:&quot;)
length(bmj_links)

# download html content from webpage
# save to output/fulltexts/bmj</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (html) from BMJ:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (html) from BMJ:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/bmj&quot;),
                  recursive = TRUE,
             pattern = &quot;\\.html$&quot;
)
)</code></pre>
<pre><code>[1] 4</code></pre>
</div>
<div id="download-full-text-from-cambridge" class="section level3">
<h3>Download full text from Cambridge</h3>
<p>Policies: <a
href="https://www.cambridge.org/core/services/open-research/text-and-data-mining"
class="uri">https://www.cambridge.org/core/services/open-research/text-and-data-mining</a></p>
<ul>
<li>Can carry out TDM on any Cambridge Core content you have lawful
access to</li>
<li>Contact <a href="mailto:openresearch@cambridge.org"
class="email">openresearch@cambridge.org</a> about getting xml
content</li>
</ul>
<pre class="r"><code>cambridge_doi_patterns &lt;- &quot;10.1017&quot;

cambridge_links &lt;-
  grep(cambridge_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from Cambridge:&quot;)
length(cambridge_links)

# obtain html content from webpage</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (html) from Cambridge:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (html) from Cambridge:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/cambridge&quot;),
                  recursive = TRUE,
             pattern = &quot;\\.html$&quot;
)
)</code></pre>
<pre><code>[1] 1</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (xml) from Cambridge:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Cambridge:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/cambridge&quot;),
                  recursive = TRUE,
             pattern = &quot;\\.xml$&quot;
)
)</code></pre>
<pre><code>[1] 0</code></pre>
</div>
<div id="download-full-text-from-oxford-academic"
class="section level3">
<h3>Download full text from Oxford Academic</h3>
<p>Oxford Academic TDM policy: <a
href="https://academic.oup.com/pages/purchasing/rights-and-permissions/text-and-data-mining"
class="uri">https://academic.oup.com/pages/purchasing/rights-and-permissions/text-and-data-mining</a></p>
<p>*should reach out to confirm UCSF rights / possibly get xml
formats</p>
<pre class="r"><code># go doi pages, and download html manually 
oxford_dois &lt;- grep(&quot;10.1093|10.113/amiajnl|10.1210|10.1513&quot;, 
                   doi_information$DOI, 
                   value = TRUE)

print(&quot;Number of papers potentially can get from Oxford Academic:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from Oxford Academic:&quot;</code></pre>
<pre class="r"><code>length(oxford_dois)</code></pre>
<pre><code>[1] 38</code></pre>
<pre class="r"><code># then had to download manually using institutional login
# then saved to output/fulltexts/oxford_academic/html
oxford_htmls &lt;- list.files(here::here(&quot;output/fulltexts/oxford_academic/html/&quot;),
                             pattern = &quot;\\.html$&quot;
                             )

print(&quot;Number of downloaded full text files (html) from Oxford Academic:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (html) from Oxford Academic:&quot;</code></pre>
<pre class="r"><code>length(oxford_htmls)</code></pre>
<pre><code>[1] 39</code></pre>
<div id="convert-html-to-txt-files" class="section level4">
<h4>Convert html to txt files</h4>
<pre class="r"><code># convert html to txt

for(html_file in oxford_htmls){
  
  html_path &lt;- here::here(&quot;output/fulltexts/oxford_academic/html/&quot;,
                          html_file
                          )
  
  html_content &lt;- rvest::read_html(html_path)
  
  text_content &lt;- rvest::html_text2(html_content)
  
  writeLines(text_content,
             here::here(&quot;output/fulltexts/oxford_academic/txt/&quot;,
                        gsub(&quot;\\.html$&quot;, &quot;.txt&quot;, html_file)
                        ),
             useBytes = TRUE)
  
}</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (html) from Oxford Academic:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (html) from Oxford Academic:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/oxford_academic/html&quot;),
                  pattern = &quot;\\.html$&quot;
)
)</code></pre>
<pre><code>[1] 39</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (txt) from Oxford Academic:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (txt) from Oxford Academic:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/oxford_academic/txt&quot;),
                  pattern = &quot;\\.txt$&quot;
)
)</code></pre>
<pre><code>[1] 35</code></pre>
</div>
</div>
<div id="download-full-text-from-taylor-francis" class="section level3">
<h3>Download full text from Taylor &amp; Francis</h3>
<p>TDM policy / information: <a
href="https://taylorandfrancis.com/our-policies/textanddatamining/"
class="uri">https://taylorandfrancis.com/our-policies/textanddatamining/</a></p>
<ul>
<li>” If you or your institution subscribes to content from Taylor &amp;
Francis you can carry out TDM activities on this content, as well as
open access content, without any additional charge, provided this is on
a non-commercial basis. ”</li>
</ul>
<pre class="r"><code>taylor_francis_dois &lt;- grep(&quot;10.1080|10.2217&quot;, 
                   doi_information$DOI,
                   value = TRUE)

print(&quot;Number of papers potentially can get from Taylor &amp; Francis:&quot;)
length(taylor_francis_dois)

# then had to download manually using institutional login
# as html
# saved to output/fulltexts/taylor_and_francis/html</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (html) from Taylor &amp; Francis:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (html) from Taylor &amp; Francis:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/taylor_and_francis/html&quot;),
                  pattern = &quot;\\.html$&quot;
)
)</code></pre>
<pre><code>[1] 3</code></pre>
<pre class="r"><code>print(&quot;Number of downloaded full text files (xml) from Taylor &amp; Francis:&quot;)</code></pre>
<pre><code>[1] &quot;Number of downloaded full text files (xml) from Taylor &amp; Francis:&quot;</code></pre>
<pre class="r"><code>length(list.files(here::here(&quot;output/fulltexts/taylor_and_francis&quot;),
                  recursive = TRUE,
                  pattern = &quot;\\.xml$&quot;)
)</code></pre>
<pre><code>[1] 0</code></pre>
</div>
</div>
</div>
<div id="to-get-text-mining-license-info-for" class="section level1">
<h1>To get text-mining license info for:</h1>
<p>American Physiological Society, doi: 10.1152</p>
<pre class="r"><code># check, how many papers:
aps_doi_patterns &lt;- &quot;10.1152&quot;

aps_links &lt;-
  grep(aps_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from APS:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from APS:&quot;</code></pre>
<pre class="r"><code>length(aps_links)</code></pre>
<pre><code>[1] 2</code></pre>
<p>American Association for Cancer Research, doi: 10.1158</p>
<pre class="r"><code>aacr_doi_patterns &lt;- &quot;10.1158&quot;

aacr_links &lt;-
  grep(aacr_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from AACR:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from AACR:&quot;</code></pre>
<pre class="r"><code>length(aacr_links)</code></pre>
<pre><code>[1] 4</code></pre>
<p>AHA, doi: 10.1161</p>
<pre class="r"><code>aha_doi_patterns &lt;- &quot;10.1161&quot;

aha_links &lt;-
  grep(aha_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from AHA:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from AHA:&quot;</code></pre>
<pre class="r"><code>length(aha_links)</code></pre>
<pre><code>[1] 4</code></pre>
<p>? ATS: doi: 10.1164, 10.1165 (moving to Oxford Academic in March
2026)</p>
<pre class="r"><code>ats_doi_patterns &lt;- &quot;10.1164|10.1165&quot;

ats_links &lt;-
  grep(ats_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from ATS:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from ATS:&quot;</code></pre>
<pre class="r"><code>length(ats_links)</code></pre>
<pre><code>[1] 12</code></pre>
<p>ASH, doi: 10.1182</p>
<pre class="r"><code>ash_doi_patterns &lt;- &quot;10.1182&quot;

ash_links &lt;-
  grep(ash_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from ASH:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from ASH:&quot;</code></pre>
<pre class="r"><code>length(ash_links)</code></pre>
<pre><code>[1] 1</code></pre>
<p>ERS, doi: 10.1183</p>
<pre class="r"><code>ers_doi_patterns &lt;- &quot;10.1183&quot;

ers_links &lt;-
  grep(ers_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from ERS:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from ERS:&quot;</code></pre>
<pre class="r"><code>length(ers_links)</code></pre>
<pre><code>[1] 1</code></pre>
<p>ASCO, doi: 10.1200</p>
<pre class="r"><code>asco_doi_patterns &lt;- &quot;10.1200&quot;

asco_links &lt;-
  grep(asco_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from ASCO:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from ASCO:&quot;</code></pre>
<pre class="r"><code>length(asco_links)</code></pre>
<pre><code>[1] 1</code></pre>
<p>AAN, doi: 10.1212</p>
<pre class="r"><code>aan_doi_patterns &lt;- &quot;10.1212&quot;

aan_links &lt;-
  grep(aan_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from AAN:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from AAN:&quot;</code></pre>
<pre class="r"><code>length(aan_links)</code></pre>
<pre><code>[1] 3</code></pre>
<p>J-STAGE: doi: 10.1248</p>
<pre class="r"><code>jstage_doi_patterns &lt;- &quot;10.1248&quot;

jstage_links &lt;-
  grep(jstage_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from J-STAGE:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from J-STAGE:&quot;</code></pre>
<pre class="r"><code>length(jstage_links)</code></pre>
<pre><code>[1] 1</code></pre>
<p>JASN: doi: 10.1681</p>
<pre class="r"><code>jasn_doi_patterns &lt;- &quot;10.1681&quot;

jasn_links &lt;-
  grep(jasn_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from JASN:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from JASN:&quot;</code></pre>
<pre class="r"><code>length(jasn_links)</code></pre>
<pre><code>[1] 4</code></pre>
<p>(ADA) Diabetes, doi: 10.2337</p>
<ul>
<li><a
href="https://diabetesjournals.org/journals/pages/ada-journal-policies"
class="uri">https://diabetesjournals.org/journals/pages/ada-journal-policies</a></li>
<li>? Seems likely text-mining may be allowed, <a
href="https://diabetesjournals.org/journals/pages/license"
class="uri">https://diabetesjournals.org/journals/pages/license</a></li>
</ul>
<pre class="r"><code>diabetes_doi_patterns &lt;- &quot;10.2337&quot;

diabetes_links &lt;-
  grep(diabetes_doi_patterns,
       doi_information$DOI,
       value = TRUE)

print(&quot;Number of papers potentially can get from Diabetes:&quot;)</code></pre>
<pre><code>[1] &quot;Number of papers potentially can get from Diabetes:&quot;</code></pre>
<pre class="r"><code>length(diabetes_links)</code></pre>
<pre><code>[1] 12</code></pre>
</div>
<div id="download-text-with-crossref-link-help" class="section level1">
<h1>Download text with Crossref link help:</h1>
<pre class="r"><code>downloaded_pmids &lt;- list.files(here::here(&quot;output/fulltexts/&quot;),
                               recursive = TRUE,
                               pattern = &quot;\\.xml$&quot;
                               )

not_available&lt;-
not_available[!(not_available %in% additional_downloaded_pmids)]

remaining_doi_info &lt;-
converted_ids |&gt;
  filter(PMID %in% not_available) |&gt;
  filter(DOI != &quot;&quot;) |&gt;
  pull(DOI)

library(rcrossref)
library(httr)

# Get download links from Crossref
get_crossref_links &lt;- function(doi) {
  
  #browser()
  
  # Query Crossref for the article
  works &lt;- cr_works(dois = doi)
  
  # keep links for xml or text-mining 
  links &lt;- works$data$link[[1]]
  
  if(is.null(links)){
    link_data &lt;- data.frame(doi = doi,
                            URL = NA,
                            content.type = NA,
                            content.version = NA,
                            intended.application = NA)
    return(link_data)
  }
  
  links &lt;- 
  links |&gt;
    filter(intended.application == &quot;text-mining&quot; | content.type == &quot;application/xml&quot;
             ) 
  
  
  
  if(nrow(links) == 0){
    link_data &lt;- data.frame(doi = doi,
                            URL = NA,
                            content.type = NA,
                            content.version = NA,
                            intended.application = NA)
  } else{
  
  link_data &lt;- 
  data.frame(doi = doi,
             links)
  
  }

  return(link_data)
} 

# remaining_doi_info &lt;- 
# doi_information |&gt;
#   filter(!c(DOI %in% paste0(&quot;https://doi.org/&quot;,
#                             springer_nature_links)
#             )
#          ) |&gt;
#   pull(DOI)

# # add nature links that I couldn&#39;t download before
# undownloaded_nature_links &lt;- 
# oa_status_df |&gt;
#   filter(openaccess == FALSE) |&gt;
#   pull(doi) 
  
# remaining_doi_info &lt;- 
#   c(remaining_doi_info, 
#     undownloaded_nature_links
#     )

length(remaining_doi_info)

remaining_doi_info  &lt;- str_remove_all(remaining_doi_info,
                                        &quot;https://doi.org/&quot;
                                        )

link_df &lt;- purrr::map(remaining_doi_info, 
                      ~get_crossref_links(.x)) |&gt; 
  bind_rows()

link_df |&gt;
  filter(!is.na(URL)) |&gt;
  pull(doi) |&gt;
  unique() |&gt;
  length()</code></pre>
<div id="use-elsevier-api-links-to-download-full-text-xml"
class="section level2">
<h2>Use elsevier API links to download full text XML</h2>
<pre class="r"><code>elsevier_links_to_download &lt;-
link_df |&gt;
  filter(grepl(&quot;api.elsevier.com&quot;, URL)
         ) |&gt;
  filter(
  grepl(&quot;xml&quot;, content.type) 
  ) 

pmids_more_links &lt;- 
doi_information |&gt;
  filter(DOI %in% paste0(&quot;https://doi.org/&quot;,
                        elsevier_links_to_download$doi)
         ) |&gt;
  pull(PMID) 


# Function to check if article is open access
# is_open_access &lt;- function(res) {
#   doc &lt;- content(res)
#   xml2::xml_ns_strip(doc)
#   
#   # Find the open access status element
#   oa_status &lt;- xml2::xml_find_first(doc, &quot;.//oa-article-status|.//xocs:open-access&quot;)
#   
#   if (is.na(oa_status)) {
#     return(NA)  # Status not found
#   }
#   
#   # Check the attributes
#   is_oa &lt;- xml2::xml_attr(oa_status, &quot;is-open-access&quot;)
#   is_archive &lt;- xml2::xml_attr(oa_status, &quot;is-open-archive&quot;)
#   
#   # Return TRUE only if is-open-access=&quot;1&quot; or is-open-archive=&quot;1&quot;
#   return(is_oa == &quot;1&quot; || is_archive == &quot;1&quot;)
# }

# Function to download full text from Elsevier API link
download_elsevier_text &lt;- function(url, 
                                   api_key,
                                   pmid,
                                   out_dir = here::here(&quot;output/fulltexts/elsevier/&quot;)) {
  
  if(file.exists(paste0(out_dir, pmid, &quot;.xml&quot;))){
    return(TRUE)
  }
  
  response &lt;- GET(url,
                  add_headers(&quot;X-ELS-APIKey&quot; = api_key)
                  )
  
  if (status_code(response) != 200) {
    message(&quot;Failed to fetch XML for &quot;, pmid)
    return(FALSE)
    
  } 
  
  # browser()
  # 
  # 
  # if (is_open_access(response)) {
  #   message(&quot;Article is not open access for &quot;, pmid)
  #   return(FALSE)
  # }
  
  doc &lt;- content(response)
  
  # Option 1: Use xml_ns() to get namespaces and reference them
  ns &lt;- xml2::xml_ns(doc)
  original_text &lt;- xml2::xml_find_first(doc, &quot;.//d1:originalText&quot;, ns)
  
  # xml_content &lt;- xml2::xml_find_first(content(response), 
  #                                        &quot;.//originalText&quot;)
  
  xml2::write_xml(original_text,
            paste0(out_dir, pmid, &quot;.xml&quot;)
  )
  
}

purrr::walk2(elsevier_links_to_download$URL,
               pmids_more_links,
               ~download_elsevier_text(url = .x,
                                       api_key = elsevier_api,
                                       pmid = .y)
               )

elsevier_links_to_download &lt;-
link_df |&gt;
  filter(grepl(&quot;api.elsevier.com&quot;, URL)
         ) |&gt;
  filter(
  grepl(&quot;plain&quot;, content.type) 
  ) 

pmids_more_links &lt;- 
doi_information |&gt;
  filter(DOI %in% paste0(&quot;https://doi.org/&quot;,
                        elsevier_links_to_download$doi)
         ) |&gt;
  pull(PMID) 

download_elsevier_text &lt;- function(url, 
                                   api_key,
                                   pmid,
                                   out_dir = here::here(&quot;output/fulltexts/elsevier/&quot;)) {
  
  if(file.exists(paste0(out_dir, pmid, &quot;.xml&quot;))){
    return(TRUE)
  }
  
  response &lt;- GET(url,
                  add_headers(&quot;X-ELS-APIKey&quot; = api_key)
                  )
  
  if (status_code(response) != 200) {
    message(&quot;Failed to fetch text for &quot;, pmid)
    return(FALSE)
    
  }
  
  text_content &lt;- content(response, 
                          as = &quot;text&quot;, 
                          encoding = &quot;UTF-8&quot;)
  
  writeLines(text_content,
             paste0(out_dir, pmid, &quot;.txt&quot;),
             useBytes = TRUE)
  
}

purrr::walk2(elsevier_links_to_download$URL,
               pmids_more_links,
               ~download_elsevier_text(url = .x,
                                       api_key = elsevier_api,
                                       pmid = .y)
               )
                
retrieved_pmids &lt;- 
  list.files(here::here(&quot;output/fulltexts/elsevier/&quot;),
             pattern = &quot;\\.xml$|\\.txt$&quot;
             )
retrieved_pmids &lt;- sub(&quot;\\.xml$|\\.txt$&quot;, &quot;&quot;, retrieved_pmids)
     
downloaded_elsevier_dois &lt;-
doi_information |&gt;
  filter(PMID %in% retrieved_pmids) |&gt;
  pull(DOI)

remaining_doi_info &lt;-
remaining_doi_info[!c(remaining_doi_info %in% downloaded_elsevier_dois)] </code></pre>
</div>
<div id="other-open-alex-wiley-links" class="section level2">
<h2>other open alex wiley links</h2>
<pre class="r"><code>open_alex_wiley_urls &lt;-
open_alex_works |&gt; 
  filter(doi %in% paste0(&quot;https://doi.org/&quot;, remaining_doi_info)) |&gt; 
  filter(is_oa_anywhere == T) |&gt; 
  filter(grepl(&quot;onlinelibrary.wiley.com&quot;, oa_url)) 

open_alex_wiley_dois &lt;-
open_alex_wiley_urls |&gt;
  pull(doi)

doi_information |&gt;
  filter(DOI %in% open_alex_wiley_dois
         ) |&gt;
  pull(PMID) -&gt; pmids_open_alex_wiley

purrr::walk2(open_alex_wiley_urls$oa_url,
             pmids_open_alex_wiley,
             ~ download_wiley_pdf(doi = .x,
                                  api_key = wiley_api,
                                  pmids = .y)
             )</code></pre>
</div>
</div>
<div id="download-pdfs-using-open-access-information-from-open-alex"
class="section level1">
<h1>Download PDFs using Open Access information from Open Alex</h1>
<div id="pmids-that-couldnt-be-converted-to-pmcids"
class="section level3">
<h3>PMIDs that couldn’t be converted to PMCIDs</h3>
<pre class="r"><code># old getting dois:
entrez_info &lt;-
entrez_summary(db=&quot;pubmed&quot;, 
               id=not_convertable_pmids)

dois &lt;-
entrez_info |&gt;
  purrr::map(function(x) {
    
    x$articleids |&gt; 
      filter(idtype == &quot;doi&quot;) |&gt; 
      pull(value)
  }
)</code></pre>
<pre class="r"><code>library(openalexR)

convert_pmid_df &lt;- fread(here::here(&quot;data/europe_pmc/PMID_PMCID_DOI.csv&quot;))

not_convertable_pmids &lt;- converted_ids |&gt; 
                         filter(pmcids == &quot;&quot;) |&gt; 
                         pull(PMID)

doi_information &lt;-
convert_pmid_df |&gt;
  filter(PMID %in% not_convertable_pmids)

doi_information |&gt;
  filter(DOI == &quot;&quot;)

doi_information$PMID |&gt; unique() |&gt; length()

length(not_convertable_pmids)

# get open alex works for pmids
open_alex_works &lt;- oa_fetch(
  doi = unique(doi_information$DOI),
  entity = &quot;works&quot;,
  options = list(select = c(&quot;doi&quot;, 
                            &quot;open_access&quot;))
)

# no best open access location: 
open_alex_works |&gt; 
  filter(is.na(oa_url)) |&gt;
  nrow()

# pdf link available:
open_alex_works |&gt; 
  filter(grepl(&quot;pdf&quot;, oa_url)) |&gt;
  nrow()

to_download_pdfs &lt;-
open_alex_works |&gt; 
  filter(grepl(&quot;.pdf&quot;, oa_url)) |&gt;
  pull(oa_url)

  writeLines(
    to_download_pdfs,
    here::here(&quot;output/fulltexts/pdfs/pdf_links_to_download.txt&quot;))</code></pre>
<pre class="bash"><code>
cd output/fulltexts/pdfs

while read -r url; do
  curl -O &quot;$url&quot;
done &lt; pdf_links_to_download.txt
</code></pre>
</div>
<div id="pmcids-not-found-in-author-manuscripts-or-open-access-sections"
class="section level3">
<h3>PMCIDs not found in Author Manuscripts or Open Access sections</h3>
<pre class="r"><code>doi_information &lt;-
convert_pmid_df |&gt;
  filter(PMCID %in% not_available)

doi_information |&gt;
  filter(DOI == &quot;&quot;)

doi_information &lt;-
  doi_information |&gt;
  filter(DOI != &quot;&quot;)

# get open alex works for pmcids
open_alex_works &lt;- oa_fetch(
  doi = doi_information$DOI,
  entity = &quot;works&quot;,
  options = list(select = c(#&quot;title&quot;,
                            &quot;doi&quot;, 
                            &quot;open_access&quot;
                            ))
)

# no best open access location: 
open_alex_works |&gt; 
  filter(is.na(oa_url)) |&gt;
  nrow()

# pdf link available:
open_alex_works |&gt; 
  filter(grepl(&quot;pdf&quot;, oa_url)) |&gt;
  nrow()

to_download_pdfs &lt;-
open_alex_works |&gt; 
  filter(grepl(&quot;.pdf&quot;, oa_url)) |&gt;
  pull(oa_url)

  writeLines(
    to_download_pdfs,
    here::here(&quot;output/fulltexts/pdfs/pdf_links_to_download_pt2.txt&quot;))</code></pre>
<pre class="bash"><code>
cd output/fulltexts/pdfs

while read -r url; do
  curl -O &quot;$url&quot;
done &lt; pdf_links_to_download_pt2.txt
</code></pre>
</div>
</div>
<div id="test-not-used---europe-pmc-author-manuscripts"
class="section level1">
<h1>Test: not used - Europe PMC Author Manuscripts</h1>
<pre class="bash"><code>
curl -s https://europepmc.org/ftp/manuscripts/ \
  | grep -o &#39;author_manuscript_txt[^&quot;]*\.filelist\.txt&#39; \
  | sort -u \
  | while read -r file; do
      curl -O &quot;https://europepmc.org/ftp/manuscripts/$file&quot;
    done
</code></pre>
<pre class="r"><code>all_file_lists &lt;- list.files(here::here(&quot;data/epmc&quot;))

author_manu_epmc &lt;- all_file_lists |&gt;
                    purrr::map(function(file_name) {
                      
                      file_path = here::here(&quot;data/epmc&quot;,
                                             file_name
                                             )
                      
                      df &lt;- fread(file_path)
                      
                      return(df)
                    }
                    ) |&gt;
                    bind_rows()

author_manu_epmc |&gt;
  filter(AccessionID %in% not_available)

author_manu_epmc |&gt;
  filter(PMID %in% not_avaliable_pmids)

author_manu_epmc |&gt;
  filter(PMID %in% pmids)

author_manu_epmc |&gt;
  filter(PMID %in% not_convertable_pmids)</code></pre>
</div>
<div id="test-not-used---download-with-ftp-service-where-avaliable"
class="section level1">
<h1>Test: not used - Download with ftp service, where avaliable</h1>
<pre class="r"><code># not_available
not_convertable_pmids &lt;- converted_ids |&gt; 
                         filter(pmcids == &quot;&quot;) |&gt; 
                         pull(PMID)

all_tgz_links = c()

for(article_id in &quot;PMC2613843&quot;){

url &lt;- paste0(&quot;https://www.ncbi.nlm.nih.gov/pmc/utils/oa/oa.fcgi?id=&quot;,
              article_id)
  
resp &lt;- GET(url)

xml_data &lt;- xml_child(content(resp), &quot;records&quot;)

tgz_link &lt;- xml_find_first(xml_data, 
                           &quot;.//link[@format=&#39;tgz&#39;]/@href&quot;)
tgz_link &lt;- xml_text(tgz_link)

if (is.na(tgz_link)) {
  
  print(&quot;No tar.gz link found.&quot;)
  
} else {
  
  all_tgz_links &lt;- append(all_tgz_links, 
                          tgz_link)
  
}
}</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.1 (2023-06-16)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS 15.7.3

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Los_Angeles
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
[1] rcrossref_1.2.1   data.table_1.17.8 dplyr_1.1.4       here_1.0.1       
[5] stringr_1.6.0     xml2_1.4.0        httr_1.4.7        workflowr_1.7.1  

loaded via a namespace (and not attached):
 [1] sass_0.4.10         generics_0.1.4      renv_1.0.3         
 [4] stringi_1.8.7       httpcode_0.3.0      digest_0.6.37      
 [7] magrittr_2.0.4      evaluate_1.0.5      fastmap_1.2.0      
[10] plyr_1.8.9          rprojroot_2.1.0     jsonlite_2.0.0     
[13] processx_3.8.6      whisker_0.4.1       crul_1.6.0         
[16] ps_1.9.1            promises_1.3.3      BiocManager_1.30.26
[19] jquerylib_0.1.4     cli_3.6.5           shiny_1.11.1       
[22] rlang_1.1.6         withr_3.0.2         cachem_1.1.0       
[25] yaml_2.3.10         tools_4.3.1         httpuv_1.6.16      
[28] DT_0.34.0           curl_7.0.0          vctrs_0.6.5        
[31] R6_2.6.1            mime_0.13           lifecycle_1.0.4    
[34] git2r_0.36.2        fs_1.6.6            htmlwidgets_1.6.4  
[37] miniUI_0.1.2        pkgconfig_2.0.3     callr_3.7.6        
[40] pillar_1.11.1       bslib_0.9.0         later_1.4.4        
[43] glue_1.8.0          Rcpp_1.1.0          xfun_0.55          
[46] tibble_3.3.0        tidyselect_1.2.1    rstudioapi_0.17.1  
[49] knitr_1.50          xtable_1.8-4        htmltools_0.5.8.1  
[52] rmarkdown_2.30      compiler_4.3.1      getPass_0.2-4      </code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
